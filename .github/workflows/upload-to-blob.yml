name: Upload Cleaned Sales Data to Azure Blob Storage

on:
  push:
    paths:
      - 'data/processed/sales_clean.csv'
      - '.github/workflows/upload-to-blob.yml'
  workflow_dispatch:

jobs:
  upload-to-blob:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout the code from the repository
      - name: Checkout code
        uses: actions/checkout@v4

      # Step 2: Set up Python environment (if needed for further scripting)
      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      # Step 3: Ensure Azure CLI is installed
      # Most GitHub Actions runners already include Azure CLI.
      # This step is optional but guarantees az CLI availability.
      - name: Ensure Azure CLI is installed
        run: |
          if ! command -v az &> /dev/null
          then
            echo "Azure CLI not found, installing..."
            curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash
          else
            echo "Azure CLI is already installed."
          fi

      # Step 4: Authenticate to Azure using Service Principal credentials
      # Credentials are securely stored as a GitHub secret (AZURE_CREDENTIALS)
      - name: Login to Azure using Service Principal
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      # Step 5: Upload the cleaned sales data CSV to Azure Blob Storage
      # Uses Azure CLI to upload the file to the specified storage account and container
      - name: Upload sales_clean.csv to Azure Blob Storage
        run: |
          az storage blob upload \
            --account-name etlstoragedemoalex \
            --container-name raw \
            --file data/processed/sales_clean.csv \
            --name sales_clean.csv \
            --auth-mode login

